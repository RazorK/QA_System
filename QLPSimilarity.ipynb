{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQLPSortedIndexList(question, cv, tf, lda,cwlist, lam, u):\n",
    "    # should return list of \n",
    "    simiList = []\n",
    "    qes = cv.transform([question.content])[0].toarray()[0]\n",
    "    for row in tf:\n",
    "        prob = 1\n",
    "        answerDis = lda.transform([row]).tolist()[0]\n",
    "        for i in range(len(qes)):\n",
    "            if(qes[i] == 0): continue\n",
    "            pseudo = (row[i] + u * cwlist[i]) / (u + sum(row))\n",
    "            \n",
    "            # calculate plda\n",
    "            plda = 0\n",
    "            \n",
    "            # traverse topic\n",
    "            for topic_idx, topic in enumerate(lda.components_):\n",
    "                plda += answerDis[topic_idx] * topic.item(i)*qes[i]\n",
    "                \n",
    "            prob *= lam*pseudo + (1-lam) * plda\n",
    "        \n",
    "        simiList.append(prob)\n",
    "    # sort the similarity list, and return the index list.\n",
    "    res = list(range(len(simiList)))\n",
    "    return sorted(res, key = lambda i : simiList[i], reverse= True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, cv, answers, word_ratio = generate_count_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=300,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=300, mean_change_tol=0.001,\n",
       "             n_components=51, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n",
      "[0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.7898537555278093, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.19750434560736937, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997, 0.00025799793601675997]\n"
     ]
    }
   ],
   "source": [
    "row = X[2]\n",
    "print(row)\n",
    "d = lda.transform([row]).tolist()[0]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = answers[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 75, 484, 557, 10, 436, 386, 401, 553, 443, 390, 545, 224, 477, 379, 488, 324, 270, 173, 492, 550, 578, 326, 422, 430, 426, 513, 406, 522, 199, 434, 566, 455, 423, 320, 415, 554, 352, 323, 402, 487, 429, 463, 269, 360, 504, 437, 441, 399, 514, 466, 534, 570, 520, 421, 439, 531, 593, 395, 509, 201, 8, 460, 467, 416, 473, 292, 310, 497, 480, 266, 451, 479, 242, 380, 456, 502, 410, 470, 474, 227, 580, 594, 501, 582, 392, 599, 458, 211, 425, 495, 273, 419, 296, 475, 457, 568, 483, 260, 440, 462, 397, 579, 325, 503, 222, 530, 393, 248, 468, 308, 432, 572, 560, 563, 231, 573, 461, 302, 542, 215, 527, 362, 405, 418, 486, 555, 450, 548, 435, 589, 538, 261, 588, 567, 347, 590, 596, 576, 539, 581, 528, 333, 376, 544, 396, 218, 369, 367, 281, 295, 583, 398, 312, 510, 587, 481, 449, 284, 446, 597, 523, 547, 283, 506, 533, 512, 552, 372, 404, 517, 453, 303, 304, 489, 519, 464, 595, 348, 389, 354, 476, 253, 592, 459, 412, 543, 403, 518, 330, 252, 365, 516, 341, 318, 431, 272, 275, 317, 417, 549, 230, 564, 342, 508, 585, 427, 288, 505, 500, 243, 203, 482, 278, 340, 366, 472, 343, 374, 257, 586, 493, 577, 499, 359, 569, 584, 314, 363, 268, 316, 558, 571, 338, 321, 277, 525, 428, 371, 226, 259, 364, 336, 511, 319, 345, 291, 561, 337, 391, 208, 315, 332, 358, 262, 285, 210, 192, 469, 172, 280, 494, 34, 373, 327, 244, 149, 256, 559, 532, 377, 298, 420, 381, 591, 258, 301, 424, 160, 556, 521, 286, 134, 131, 413, 267, 535, 382, 141, 409, 148, 236, 159, 282, 274, 220, 540, 309, 385, 191, 168, 355, 48, 290, 445, 307, 490, 471, 205, 339, 574, 361, 1, 331, 598, 524, 255, 551, 297, 264, 24, 223, 408, 378, 177, 313, 498, 204, 142, 452, 225, 182, 444, 357, 57, 7, 384, 541, 546, 114, 178, 491, 485, 187, 271, 125, 151, 350, 575, 507, 537, 135, 407, 300, 232, 188, 279, 329, 207, 344, 213, 562, 263, 265, 394, 346, 414, 239, 116, 370, 351, 212, 33, 287, 400, 529, 305, 145, 294, 163, 293, 368, 335, 130, 165, 36, 193, 166, 179, 536, 383, 254, 138, 433, 167, 228, 238, 353, 442, 276, 9, 311, 306, 334, 143, 115, 221, 526, 189, 299, 117, 387, 103, 156, 147, 375, 289, 140, 349, 478, 194, 246, 139, 388, 157, 136, 118, 411, 132, 454, 100, 152, 245, 249, 41, 565, 78, 87, 124, 195, 76, 154, 515, 181, 77, 184, 88, 129, 83, 106, 200, 121, 169, 69, 158, 219, 174, 0, 112, 122, 111, 216, 96, 251, 105, 110, 62, 2, 356, 217, 153, 196, 198, 233, 102, 28, 4, 47, 90, 465, 180, 328, 250, 25, 42, 52, 6, 70, 82, 61, 49, 31, 65, 30, 68, 29, 84, 13, 51, 438, 98, 40, 229, 109, 64, 108, 101, 15, 80, 5, 185, 234, 79, 21, 104, 11, 107, 16, 14, 447, 91, 237, 54, 119, 206, 46, 176, 12, 95, 171, 27, 44, 94, 35, 20, 45, 18, 56, 214, 66, 164, 161, 137, 241, 175, 133, 86, 85, 37, 155, 150, 186, 19, 146, 123, 144, 496, 97, 32, 92, 128, 38, 209, 73, 240, 202, 71, 127, 120, 183, 58, 67, 60, 59, 43, 53, 170, 39, 190, 126, 23, 162, 74, 89, 22, 197, 3, 113, 50, 247, 26, 63, 322, 93, 99, 448, 55, 72, 81, 235]\n"
     ]
    }
   ],
   "source": [
    "l = getQLPSortedIndexList(ques, cv, X, lda, word_ratio, 0, 1)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "227"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(cv.transform([ques.content])[0].toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_feature_names = cv.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "simiList = [3,2,1,5,9]\n",
    "res = list(range(len(simiList)))\n",
    "print(sorted(res, key = lambda i : simiList[i], reverse= True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
