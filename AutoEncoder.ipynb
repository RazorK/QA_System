{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 60\n",
    "LR = 0.005         # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, cv, answers, word_ratio = generate_count_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_sz = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.from_numpy(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([600, 7574])\n"
     ]
    }
   ],
   "source": [
    "print(train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(x, batch_size=100):\n",
    "    n_batches = len(x)//batch_size\n",
    "    x = x[:n_batches*batch_size]\n",
    "    for ii in range(0, len(x), batch_size):\n",
    "        yield x[ii:ii+batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 7574])\n",
      "torch.Size([100, 7574])\n",
      "torch.Size([100, 7574])\n",
      "torch.Size([100, 7574])\n",
      "torch.Size([100, 7574])\n",
      "torch.Size([100, 7574])\n"
     ]
    }
   ],
   "source": [
    "for ii, x in enumerate(get_batches(train, 100), 1):\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(vol_sz, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 32),   # compress to 3 features which can be visualized in plt\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(32, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, vol_sz),\n",
    "            nn.Sigmoid(),       # compress to a range (0, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=7574, out_features=512, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=128, out_features=32, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=512, out_features=7574, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\envs\\py3\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 0.0417\n",
      "Epoch:  0 | train loss: 0.0297\n",
      "Epoch:  5 | train loss: 0.0413\n",
      "Epoch:  5 | train loss: 0.0298\n",
      "Epoch:  9 | train loss: 0.0414\n",
      "Epoch:  9 | train loss: 0.0297\n"
     ]
    }
   ],
   "source": [
    "autoencoder = AutoEncoder()\n",
    "print(autoencoder)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "autoencoder.train()\n",
    "for epoch in range(EPOCH):\n",
    "    for step, x in enumerate(get_batches(train, BATCH_SIZE), 1):\n",
    "        b_x = Variable(x.view(-1, vol_sz)).float()   # batch x, shape (batch, 28*28)\n",
    "        b_y = Variable(x.view(-1, vol_sz)).float()   # batch y, shape (batch, 28*28)\n",
    "\n",
    "        encoded, decoded = autoencoder(b_x)\n",
    "\n",
    "        loss = loss_func(decoded, b_y)      # mean square error\n",
    "        optimizer.zero_grad()               # clear gradients for this training step\n",
    "        loss.backward()                     # backpropagation, compute gradients\n",
    "        optimizer.step()                    # apply gradients\n",
    "        \n",
    "        if step % 5 == 0 and epoch in [0, 5, EPOCH-1]:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.data[0])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=7574, out_features=512, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=128, out_features=32, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (5): Tanh()\n",
       "    (6): Linear(in_features=512, out_features=7574, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8494, -2.9037, -1.4144, -4.9663,  2.1244,  3.6652, -3.3771,\n",
      "         0.9677,  2.4564, -2.0442, -1.3018, -3.1650,  0.5961, -3.3204,\n",
      "        -2.4065,  1.5097,  2.9149,  3.3373,  4.0288,  2.4421,  1.3653,\n",
      "        -1.7443,  3.0628,  3.7115,  3.3038, -1.6719,  3.4336, -2.3190,\n",
      "         3.5927,  3.1077, -0.4736,  2.7039])\n",
      "tensor([ 2.1554e-07,  3.1428e-07,  2.0067e-07,  ...,  1.5178e-06,\n",
      "         1.4302e-06,  2.7688e-07])\n"
     ]
    }
   ],
   "source": [
    "## evalation\n",
    "ques = answers[13]\n",
    "qes = cv.transform([ques.content])[0].toarray()[0]\n",
    "qesT = torch.from_numpy(qes).float()\n",
    "\n",
    "fea = autoencoder.encoder(qesT)\n",
    "print(fea)\n",
    "\n",
    "back = autoencoder.decoder(fea)\n",
    "print(back)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainFeatures(ae, X):\n",
    "    res = []\n",
    "    for i in range(X.shape[0]):\n",
    "        ans = torch.from_numpy(X[i]).float()\n",
    "        fea = autoencoder.encoder(ans)\n",
    "        res.append(fea)\n",
    "    return res\n",
    "\n",
    "hiddenTrain = getTrainFeatures(autoencoder, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 287, 285, 19, 367, 390, 481, 538, 332, 383, 43, 306, 394, 364, 450, 90, 52, 201, 241, 485, 37, 250, 557, 42, 505, 533, 246, 516, 361, 552, 180, 212, 405, 261, 11, 38, 100, 324, 291, 546, 369, 292, 413, 467, 318, 528, 4, 284, 20, 264, 509, 280, 506, 18, 483, 393, 514, 449, 416, 234, 508, 207, 592, 550, 544, 198, 319, 303, 215, 466, 371, 27, 415, 45, 289, 216, 189, 231, 195, 183, 379, 338, 49, 242, 524, 487, 408, 595, 522, 270, 197, 238, 10, 429, 539, 464, 382, 479, 255, 469, 9, 190, 315, 321, 248, 387, 529, 586, 460, 442, 24, 486, 317, 251, 377, 236, 542, 454, 525, 380, 560, 452, 407, 39, 526, 549, 275, 200, 521, 47, 470, 448, 0, 462, 417, 342, 354, 459, 274, 589, 323, 497, 217, 511, 253, 21, 426, 458, 534, 430, 15, 352, 357, 348, 419, 567, 358, 313, 308, 388, 294, 523, 347, 244, 391, 333, 473, 504, 553, 204, 492, 373, 199, 434, 457, 259, 513, 410, 277, 211, 482, 433, 269, 441, 392, 271, 214, 385, 283, 436, 116, 372, 493, 438, 478, 297, 368, 272, 305, 362, 554, 428, 360, 548, 276, 229, 503, 7, 35, 488, 599, 304, 202, 581, 432, 114, 58, 28, 181, 585, 465, 401, 406, 527, 376, 468, 353, 424, 51, 384, 302, 239, 418, 223, 510, 25, 219, 345, 399, 243, 237, 476, 273, 537, 184, 501, 480, 320, 425, 507, 36, 188, 208, 447, 400, 222, 403, 44, 282, 439, 260, 495, 590, 228, 446, 268, 218, 29, 54, 330, 23, 12, 31, 84, 517, 40, 240, 331, 461, 562, 451, 587, 404, 423, 5, 541, 378, 494, 350, 32, 8, 518, 597, 346, 279, 203, 576, 475, 299, 535, 296, 337, 48, 300, 520, 263, 365, 245, 489, 194, 256, 233, 530, 564, 41, 558, 232, 412, 262, 498, 187, 547, 340, 154, 444, 254, 310, 572, 281, 343, 414, 570, 316, 583, 158, 224, 574, 591, 381, 512, 422, 593, 515, 594, 14, 573, 477, 221, 16, 326, 519, 500, 402, 431, 551, 30, 366, 427, 445, 398, 440, 3, 502, 174, 456, 124, 186, 328, 474, 580, 213, 205, 563, 359, 235, 598, 490, 192, 543, 22, 230, 293, 6, 307, 258, 578, 193, 206, 220, 389, 566, 336, 411, 565, 455, 396, 301, 561, 266, 370, 596, 196, 327, 349, 46, 559, 555, 160, 363, 225, 309, 351, 249, 115, 540, 33, 579, 312, 68, 95, 484, 335, 210, 545, 472, 182, 453, 257, 1, 341, 107, 325, 286, 322, 463, 395, 57, 110, 191, 437, 420, 588, 247, 209, 339, 334, 267, 443, 344, 397, 536, 575, 290, 118, 2, 409, 298, 53, 582, 311, 185, 491, 121, 295, 355, 265, 56, 571, 314, 82, 69, 55, 278, 26, 79, 471, 329, 532, 109, 435, 117, 386, 122, 569, 179, 226, 134, 153, 375, 34, 421, 227, 499, 77, 137, 584, 577, 91, 496, 149, 17, 288, 568, 59, 169, 75, 61, 356, 105, 374, 66, 142, 65, 130, 252, 531, 111, 167, 152, 102, 125, 148, 139, 76, 96, 98, 138, 78, 86, 173, 175, 106, 556, 103, 141, 163, 108, 62, 172, 145, 92, 64, 101, 112, 131, 132, 171, 85, 119, 147, 165, 166, 129, 87, 50, 83, 143, 81, 162, 128, 97, 67, 70, 71, 146, 155, 123, 151, 136, 156, 164, 127, 94, 63, 88, 168, 157, 89, 113, 80, 60, 73, 133, 140, 178, 135, 177, 126, 104, 93, 120, 170, 161, 74, 159, 150, 99, 72, 176, 144]\n"
     ]
    }
   ],
   "source": [
    "# find the best answer\n",
    "def getIndexOrderList(ques, ansLst):\n",
    "    simiList = []\n",
    "    for ans in ansLst:\n",
    "        simiList.append(cosine_similarity(ques, ans))\n",
    "    res = list(range(len(simiList)))\n",
    "    return sorted(res, key = lambda i : simiList[i], reverse= True)\n",
    "\n",
    "print(getIndexOrderList(fea, hiddenTrain))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
